{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45127e0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45127e0e",
        "outputId": "c2e2c4d0-3792-4851-b7dd-2a12422342a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 2.298218847715843\n",
            "Mean Squared Error: 9.011497157207764\n",
            "Root Mean Squared Error: 3.001915581292679\n",
            "Model and scaler have been saved.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Load the dataset for the teaching building\n",
        "teaching_train_df = pd.read_csv('building_type_teaching_kaggle_train_dataset.csv')\n",
        "\n",
        "# Extract relevant features and target\n",
        "features = teaching_train_df[['ApparentTemperature', 'RelativeHumidity', 'CDD', 'HDD', 'Hour24', 'Minute']]  # Example features\n",
        "target = teaching_train_df['MeterReading']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Support Vector Regressor model\n",
        "svr_model = SVR()\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = svr_model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "\n",
        "# Save the trained model and scaler\n",
        "with open('teaching_svr_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(svr_model, model_file)\n",
        "with open('scaler.pkl', 'wb') as scaler_file:\n",
        "    pickle.dump(scaler, scaler_file)\n",
        "\n",
        "print(\"Model and scaler have been saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YaLTeVWQmfg",
        "outputId": "234df14d-518b-4eac-a870-e0c50b69e84c"
      },
      "id": "8YaLTeVWQmfg",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e6113325",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6113325",
        "outputId": "ce62ac35-b9c0-40dd-f3d5-e594b3bed0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "728/728 [==============================] - 6s 5ms/step - loss: 38.2936 - val_loss: 14.4718\n",
            "Epoch 2/20\n",
            "728/728 [==============================] - 3s 5ms/step - loss: 10.9465 - val_loss: 12.4027\n",
            "Epoch 3/20\n",
            "728/728 [==============================] - 5s 6ms/step - loss: 9.3292 - val_loss: 13.1718\n",
            "Epoch 4/20\n",
            "728/728 [==============================] - 5s 6ms/step - loss: 8.7418 - val_loss: 13.3150\n",
            "Epoch 5/20\n",
            "728/728 [==============================] - 3s 4ms/step - loss: 8.3138 - val_loss: 11.8125\n",
            "Epoch 6/20\n",
            "728/728 [==============================] - 3s 5ms/step - loss: 7.9593 - val_loss: 11.7849\n",
            "Epoch 7/20\n",
            "728/728 [==============================] - 5s 7ms/step - loss: 7.6410 - val_loss: 12.0589\n",
            "Epoch 8/20\n",
            "728/728 [==============================] - 1s 2ms/step - loss: 7.3985 - val_loss: 11.8571\n",
            "Epoch 9/20\n",
            "728/728 [==============================] - 1s 2ms/step - loss: 7.1817 - val_loss: 12.8388\n",
            "Epoch 10/20\n",
            "728/728 [==============================] - 1s 2ms/step - loss: 7.0245 - val_loss: 12.7236\n",
            "Epoch 11/20\n",
            "728/728 [==============================] - 2s 2ms/step - loss: 6.8427 - val_loss: 12.5248\n",
            "Epoch 12/20\n",
            "728/728 [==============================] - 2s 2ms/step - loss: 6.7171 - val_loss: 12.2474\n",
            "Epoch 13/20\n",
            "728/728 [==============================] - 1s 2ms/step - loss: 6.5631 - val_loss: 11.5985\n",
            "Epoch 14/20\n",
            "728/728 [==============================] - 2s 2ms/step - loss: 6.4641 - val_loss: 11.3713\n",
            "Epoch 15/20\n",
            "728/728 [==============================] - 3s 4ms/step - loss: 6.3753 - val_loss: 11.6102\n",
            "Epoch 16/20\n",
            "728/728 [==============================] - 2s 2ms/step - loss: 6.2706 - val_loss: 11.3844\n",
            "Epoch 17/20\n",
            "728/728 [==============================] - 1s 2ms/step - loss: 6.1934 - val_loss: 11.8237\n",
            "Epoch 18/20\n",
            "728/728 [==============================] - 1s 2ms/step - loss: 6.1055 - val_loss: 13.9431\n",
            "Epoch 19/20\n",
            "728/728 [==============================] - 1s 2ms/step - loss: 6.0430 - val_loss: 13.3102\n",
            "Epoch 20/20\n",
            "728/728 [==============================] - 2s 2ms/step - loss: 5.9807 - val_loss: 12.6696\n",
            "911/911 [==============================] - 1s 1ms/step\n",
            "Mean Absolute Error: 2.0099023533553186\n",
            "Mean Squared Error: 7.23560521564201\n",
            "Root Mean Squared Error: 2.689908031075042\n",
            "Neural network model and scaler have been saved.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Load the training dataset for the teaching building\n",
        "teaching_train_df = pd.read_csv('building_type_teaching_kaggle_train_dataset.csv')\n",
        "\n",
        "# Extract relevant features and target\n",
        "features = teaching_train_df[['ApparentTemperature', 'RelativeHumidity', 'CDD', 'HDD', 'Hour24', 'Minute']]  # Example features\n",
        "target = teaching_train_df['MeterReading']\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(features)\n",
        "y_train = target\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Save the trained model in SavedModel format\n",
        "model.save('teaching_nn_model')\n",
        "\n",
        "# Save the scaler\n",
        "with open('scaler.pkl', 'wb') as scaler_file:\n",
        "    pickle.dump(scaler, scaler_file)\n",
        "\n",
        "# Predict on the training set\n",
        "y_train_pred = model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate and print the evaluation metrics\n",
        "mae = mean_absolute_error(y_train, y_train_pred)\n",
        "mse = mean_squared_error(y_train, y_train_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "\n",
        "print(\"Neural network model and scaler have been saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c0703462",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0703462",
        "outputId": "37d3ecc4-0d63-4237-cdc9-a110643e2c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm your Energy Consumption Assistant.\n",
            "You can ask me about energy consumption predictions, usage patterns, or tips on saving energy.\n",
            "Here are some examples of what you can ask me:\n",
            "1. 'What were the usage patterns for the teaching building on 2018-10-31?'\n",
            "2. 'Can you predict the energy consumption of the teaching building for the next 30 minutes?'\n",
            "3. 'How can I lower the energy consumption of the teaching building?'\n",
            "Type 'exit' or 'quit' to end the conversation.\n",
            "\n",
            "You: How can I lower the energy consumption of the teaching building?\n",
            "\n",
            "Chatbot: Turn off lights when not in use.\n",
            "Use energy-efficient appliances.\n",
            "Regularly maintain HVAC systems.\n",
            "Utilize natural lighting during the day.\n",
            "Insulate your building properly.\n",
            "Use programmable thermostats to control heating and cooling.\n",
            "Ensure computers and other office equipment are turned off when not in use.\n",
            "Use blinds or shades to control the temperature.\n",
            "Encourage the use of stairs instead of elevators.\n",
            "Conduct regular energy audits to identify areas for improvement.\n",
            "\n",
            "You: Exit\n",
            "Goodbye! Feel free to ask me any energy-related questions anytime.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the dataset for the teaching building\n",
        "teaching_df = pd.read_csv('building_type_teaching_kaggle_train_dataset.csv')\n",
        "\n",
        "# Convert the Timestamp to datetime format and extract the date and hour\n",
        "teaching_df['Timestamp'] = pd.to_datetime(teaching_df['Timestamp'])\n",
        "teaching_df['Date'] = teaching_df['Timestamp'].dt.date\n",
        "teaching_df['Hour24'] = teaching_df['Timestamp'].dt.hour\n",
        "teaching_df['Minute'] = teaching_df['Timestamp'].dt.minute\n",
        "\n",
        "# Load the trained neural network model and scaler\n",
        "nn_model = tf.keras.models.load_model('teaching_nn_model')\n",
        "with open('scaler.pkl', 'rb') as scaler_file:\n",
        "    scaler = pickle.load(scaler_file)\n",
        "\n",
        "# Define the energy usage limit (example value)\n",
        "ENERGY_USAGE_LIMIT = 5  # kWh\n",
        "\n",
        "# Define the default current time\n",
        "current_time = pd.to_datetime('2018-10-31 23:45')\n",
        "\n",
        "def summarize_usage_patterns(date_str='2018-10-31'):\n",
        "    # Convert the date string to a datetime object\n",
        "    specific_date = pd.to_datetime(date_str).date()\n",
        "\n",
        "    # Filter data for the specific date\n",
        "    df_specific_date = teaching_df[teaching_df['Date'] == specific_date]\n",
        "\n",
        "    # Calculate average MeterReading based on 'Hour24'\n",
        "    avg_meter_reading_hourly = df_specific_date.groupby('Hour24')['MeterReading'].mean()\n",
        "\n",
        "    # Convert to numpy arrays for plotting\n",
        "    hours = avg_meter_reading_hourly.index.to_numpy()\n",
        "    avg_meter_readings = avg_meter_reading_hourly.to_numpy()\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    plt.plot(hours, avg_meter_readings, label=f'Teaching Building - {specific_date}', marker='o')\n",
        "\n",
        "    plt.title(f'Average MeterReading by Hour for Teaching Building on {specific_date}')\n",
        "    plt.xlabel('Hour (24-hour format)')\n",
        "    plt.ylabel('Average Meter Reading')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.xticks(range(0, 24))\n",
        "    plt.show()\n",
        "\n",
        "    return f\"I've displayed the average MeterReading by hour for the Teaching Building on {specific_date}.\"\n",
        "\n",
        "def predict_energy_consumption(period_minutes):\n",
        "    # Generate future time points based on the period\n",
        "    future_times = [current_time + timedelta(minutes=i) for i in range(0, period_minutes + 1, 15)]\n",
        "\n",
        "    predictions = []\n",
        "    for future_time in future_times:\n",
        "        hour = future_time.hour\n",
        "        minute = future_time.minute\n",
        "        recent_data = teaching_df.iloc[-1][['ApparentTemperature', 'RelativeHumidity', 'CDD', 'HDD']]\n",
        "        recent_data['Hour24'] = hour\n",
        "        recent_data['Minute'] = minute\n",
        "\n",
        "        features_scaled = scaler.transform([recent_data])\n",
        "        prediction = nn_model.predict(features_scaled)[0][0]\n",
        "        predictions.append((future_time, prediction))\n",
        "\n",
        "    # Generate plot\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    times = [time[0].strftime('%H:%M') for time in predictions]\n",
        "    values = [time[1] for time in predictions]\n",
        "    plt.plot(times, values, marker='o')\n",
        "\n",
        "    plt.title(f'Predicted Energy Consumption for the Next {period_minutes} Minutes')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Energy Consumption (kWh)')\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "    alerts = [pred for time, pred in predictions if pred > ENERGY_USAGE_LIMIT]\n",
        "    if alerts:\n",
        "        tips = get_energy_saving_tips()\n",
        "        alert_times = ', '.join([time.strftime('%H:%M') for time, pred in predictions if pred > ENERGY_USAGE_LIMIT])\n",
        "        return f\"Warning: Energy consumption is predicted to exceed the limit of {ENERGY_USAGE_LIMIT} kWh at {alert_times}.\\n\\nTo help reduce energy consumption, consider the following tips:\\n{tips}\"\n",
        "    else:\n",
        "        return \"Good news! The energy consumption is predicted to be within the safe limit.\"\n",
        "\n",
        "def get_energy_saving_tips():\n",
        "    tips = [\n",
        "        \"Turn off lights when not in use.\",\n",
        "        \"Use energy-efficient appliances.\",\n",
        "        \"Regularly maintain HVAC systems.\",\n",
        "        \"Utilize natural lighting during the day.\",\n",
        "        \"Insulate your building properly.\",\n",
        "        \"Use programmable thermostats to control heating and cooling.\",\n",
        "        \"Ensure computers and other office equipment are turned off when not in use.\",\n",
        "        \"Use blinds or shades to control the temperature.\",\n",
        "        \"Encourage the use of stairs instead of elevators.\",\n",
        "        \"Conduct regular energy audits to identify areas for improvement.\"\n",
        "    ]\n",
        "    return \"\\n\".join(tips)\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Hello! I'm your Energy Consumption Assistant.\")\n",
        "    print(\"You can ask me about energy consumption predictions, usage patterns, or tips on saving energy.\")\n",
        "    print(\"Here are some examples of what you can ask me:\")\n",
        "    print(\"1. 'What were the usage patterns for the teaching building on 2018-10-31?'\")\n",
        "    print(\"2. 'Can you predict the energy consumption of the teaching building for the next 30 minutes?'\")\n",
        "    print(\"3. 'How can I lower the energy consumption of the teaching building?'\")\n",
        "    print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "\n",
        "        if \"usage patterns\" in user_input.lower():\n",
        "            date_str = extract_date_from_input(user_input)\n",
        "            response = summarize_usage_patterns(date_str) if date_str else summarize_usage_patterns()\n",
        "        elif \"predict\" in user_input.lower() and \"next\" in user_input.lower():\n",
        "            period_minutes = extract_period_from_input(user_input)\n",
        "            if period_minutes:\n",
        "                response = predict_energy_consumption(period_minutes)\n",
        "            else:\n",
        "                response = \"Please provide a specific period for the prediction (e.g., next 30 minutes).\"\n",
        "        elif \"lower the energy consumption\" in user_input.lower() or \"tips\" in user_input.lower():\n",
        "            response = get_energy_saving_tips()\n",
        "        elif user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Goodbye! Feel free to ask me any energy-related questions anytime.\")\n",
        "            break\n",
        "        else:\n",
        "            response = \"I'm sorry, I don't understand that request. Could you please rephrase it?\"\n",
        "\n",
        "        print(f\"\\nChatbot: {response}\")\n",
        "\n",
        "def extract_date_from_input(user_input):\n",
        "    # Attempt to extract date using known formats\n",
        "    if \"on\" in user_input.lower():\n",
        "        date_part = user_input.lower().split(\"on\")[1].strip()\n",
        "        for fmt in (\"%Y-%m-%d\", \"%d-%m-%Y\", \"%Y/%m/%d\", \"%d/%m/%Y\"):\n",
        "            try:\n",
        "                parsed_date = datetime.strptime(date_part, fmt)\n",
        "                return parsed_date.date()\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "def extract_period_from_input(user_input):\n",
        "    # Dummy implementation to extract the period from the user input\n",
        "    if \"next\" in user_input.lower():\n",
        "        period_part = user_input.lower().split(\"next\")[1].strip().split(\" \")[0]\n",
        "        try:\n",
        "            return int(period_part)\n",
        "        except ValueError:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39127571",
      "metadata": {
        "id": "39127571"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}